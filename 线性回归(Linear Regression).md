# 线性回归(Linear Regression）

## 1.基本定义
线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。

#### 该模型基于两个定律：

大数定律：在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。

中心极限定理：一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。

## 2.优缺点

#### 优点：
* 速度快：建模速度快，不需要很复杂的计算，在数据量大的情况下依然运行速度很快。
* 可解释性好：可以根据系数给出每个变量的理解和解释

#### 缺点：
* 不能很好地拟合非线性数据。所以需要先判断变量之间是否是线性关系。

## 3.为什么在深度学习大杀四方的今天还使用线性回归呢？

一方面，线性回归所能够模拟的关系其实远不止线性关系。线性回归中的“线性”指的是系数的线性，而通过对特征的非线性变换，以及广义线性模型的推广，输出和特征之间的函数关系可以是高度非线性的。另一方面，也是更为重要的一点，线性模型的易解释性使得它在物理学、经济学、商学等领域中占据了难以取代的地位。

## 4.公式
![Regression](https://user-images.githubusercontent.com/61290493/83052905-930bc180-a015-11ea-9253-7d75e9d80c6c.png)

## 5.线性回归问什么要用最小二乘法计算？
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线的欧式距离最小之后最小。

## 6.线性回归 VS 逻辑回归

* 线性回归只能用于回归问题，逻辑回归虽然名字叫回归，但是更多用于分类问题
* 线性回归要求因变量是连续性数值变量，而逻辑回归要求因变量是离散的变量
* 线性回归要求自变量和因变量呈线性关系，而逻辑回归不要求自变量和因变量呈线性关系
* 线性回归可以直观的表达自变量和因变量之间的关系，逻辑回归则无法表达变量之间的关系

## 7.线性回归的评价指标？
#### 均方误差 MSE
测试集中的数据量m不同，因为有累加操作，所以随着数据的增加 ，误差会逐渐积累；因此衡量标准和 m 相关。为了抵消掉数据量的形象，可以除去数据量，抵消误差。通过这种处理方式得到的结果叫做 均方误差MSE（Mean Squared Error）

<img width="159" alt="MSE" src="https://user-images.githubusercontent.com/61290493/83073874-c874d700-a036-11ea-9309-2c7c9758218f.png">

#### 均方根误差 RMSE
但是使用均方误差MSE收到量纲的影响。例如在衡量房产时，y的单位是（万元），那么衡量标准得到的结果是（万元平方）。为了解决量纲的问题，可以将其开方（为了解决方差的量纲问题，将其开方得到平方差）得到均方根误差RMSE（Root Mean Squarde Error）：

<img width="273" alt="RMSE" src="https://user-images.githubusercontent.com/61290493/83073908-d9254d00-a036-11ea-831c-88502fe9629d.png">

#### 平均绝对误差MAE
对于线性回归算法还有另外一种非常朴素评测标准。要求真实值 与预测结果之间的距离最小，可以直接相减做绝对值，加m次再除以m，即可求出平均距离，被称作平均绝对误差MAE（Mean Absolute Error）.在之前确定损失函数时，我们提过，绝对值函数不是处处可导的，因此没有使用绝对值。但是在评价模型时不影响。因此模型的评价方法可以和损失函数不同。

<img width="151" alt="MAE" src="https://user-images.githubusercontent.com/61290493/83073931-e6dad280-a036-11ea-9bb7-78a8cd07c0f1.png">


