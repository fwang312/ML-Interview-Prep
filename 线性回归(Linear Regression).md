# 线性回归(Linear Regression）

## 1.基本定义
线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。

#### 该模型基于两个定律：

大数定律：在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。

中心极限定理：一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。

## 2.优缺点

#### 优点：
* 速度快：建模速度快，不需要很复杂的计算，在数据量大的情况下依然运行速度很快。
* 可解释性好：可以根据系数给出每个变量的理解和解释

#### 缺点：
* 不能很好地拟合非线性数据。所以需要先判断变量之间是否是线性关系。

## 3.为什么在深度学习大杀四方的今天还使用线性回归呢？

一方面，线性回归所能够模拟的关系其实远不止线性关系。线性回归中的“线性”指的是系数的线性，而通过对特征的非线性变换，以及广义线性模型的推广，输出和特征之间的函数关系可以是高度非线性的。另一方面，也是更为重要的一点，线性模型的易解释性使得它在物理学、经济学、商学等领域中占据了难以取代的地位。

## 4.公式
